{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c47b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_bytes(byte):\n",
    "    binary_string = \"{0:08b}\".format(byte)\n",
    "    vec = np.zeros(8)\n",
    "    for i in range(8):\n",
    "        if binary_string[i] == \"1\":\n",
    "            vec[i] = float(1) / 16\n",
    "        else:\n",
    "            vec[i] = -float(1) / 16\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte1 = 255\n",
    "byte2 = 1\n",
    "print(embed_bytes(byte1))\n",
    "print(embed_bytes(byte2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories_with_labels = [(r\"C:\\Users\\sridh\\Desktop\\smallDataset_opseq\\malware\\Benign\", 0), (r\"C:\\Users\\sridh\\Desktop\\smallDataset_opseq\\malware\\ADRD\", 1)]\n",
    "list_of_samples = []\n",
    "labels = []\n",
    "for dataset_path, label in directories_with_labels:\n",
    "    samples = [f for f in listdir(dataset_path)]\n",
    "    for file in samples:\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        list_of_samples.append(file_path)\n",
    "        labels.append(label)\n",
    "def read_file(file_path):\n",
    "    \"\"\"Read the binary sequence of a file.\"\"\"\n",
    "    with open(file_path, \"rb\") as binary_file:\n",
    "        return binary_file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 15000\n",
    "num_samples = len(list_of_samples)\n",
    "X = np.zeros((num_samples, 8, max_size))\n",
    "Y = np.asarray(labels)\n",
    "file_num = 0\n",
    "for file in tqdm(list_of_samples):\n",
    "    sample_byte_sequence = read_file(file)\n",
    "    for i in range(min(max_size, len(sample_byte_sequence))):\n",
    "           X[file_num, :, i] = embed_bytes(sample_byte_sequence[i])\n",
    "    file_num += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_gpu = True  \n",
    "use_cpu = 32 \n",
    "display_step = 10 \n",
    "test_step = 100  \n",
    "learning_rate = 0.0001  \n",
    "max_step = 500  \n",
    "batch_size = 128  \n",
    "first_n_byte = (\n",
    "    100000 \n",
    ")\n",
    "window_size = 500  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aebbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, train_label, valid_label = train_test_split(\n",
    "    list_of_samples,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=100,\n",
    ")\n",
    "\n",
    "trainset = pd.DataFrame({\"list_of_samples\": train, \"labels\": train_label})\n",
    "validset = pd.DataFrame({\"list_of_samples\": valid, \"labels\": valid_label})\n",
    "\n",
    "label_path= r\"C:/Users/sridh/Desktop/smallDataset_opseq/malware/\"\n",
    "\n",
    "trainset.to_csv(\n",
    "    label_path + \"example-train-label.csv\", index=False, header=False, encoding=\"utf-8\"\n",
    ")\n",
    "validset.to_csv(\n",
    "    label_path + \"example-valid-label.csv\", index=False, header=False, encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def write_pred(test_pred,test_idx,file_path):\n",
    "    test_pred = [item for sublist in test_pred for item in sublist]\n",
    "    with open(file_path,'w') as f:\n",
    "        for idx,pred in zip(test_idx,test_pred):\n",
    "            print(idx.upper()+','+str(pred[0]),file=f)\n",
    "\n",
    "# Dataset preparation\n",
    "class ExeDataset(Dataset):\n",
    "    def __init__(self, fp_list, data_path, label_list, first_n_byte=2000000):\n",
    "        self.fp_list = fp_list\n",
    "        self.data_path = data_path\n",
    "        self.label_list = label_list\n",
    "        self.first_n_byte = first_n_byte\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fp_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            with open(self.data_path+self.fp_list[idx],'rb') as f:\n",
    "                tmp = [i+1 for i in f.read()[:self.first_n_byte]]\n",
    "                tmp = tmp+[0]*(self.first_n_byte-len(tmp))\n",
    "        except:\n",
    "            with open(self.data_path+self.fp_list[idx].lower(),'rb') as f:\n",
    "                tmp = [i+1 for i in f.read()[:self.first_n_byte]]\n",
    "                tmp = tmp+[0]*(self.first_n_byte-len(tmp))\n",
    "\n",
    "        return np.array(tmp),np.array([self.label_list[idx]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    ExeDataset(\n",
    "        list(trainset[\"list_of_samples\"]), train, list(trainset[\"labels\"]), first_n_byte\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=use_cpu,\n",
    "    pin_memory=True,\n",
    ")\n",
    "validloader = DataLoader(\n",
    "    ExeDataset(\n",
    "        list(validset[\"list_of_samples\"]), train, list(validset[\"labels\"]), first_n_byte\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=use_cpu,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalConv(nn.Module):\n",
    "    def __init__(self,input_length=2000000,window_size=500):\n",
    "        super(MalConv, self).__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(257, 8, padding_idx=0)\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(4, 128, window_size, stride=window_size, bias=True)\n",
    "\n",
    "        self.pooling = nn.MaxPool1d(int(input_length/window_size))\n",
    "        \n",
    "\n",
    "        self.fc_1 = nn.Linear(128,128)\n",
    "        self.fc_2 = nn.Linear(128,1)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.embed(x)\n",
    "        # Channel first\n",
    "        x = torch.transpose(x,-1,-2)\n",
    "\n",
    "        cnn_value = self.conv_1(x.narrow(-2, 0, 4))\n",
    "        gating_weight = self.sigmoid(self.conv_2(x.narrow(-2, 4, 4)))\n",
    "\n",
    "        x = cnn_value * gating_weight\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        x = x.view(-1,128)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        #x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "malconv = MalConv(input_length=first_n_byte,window_size=window_size)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "adam_optim = optim.Adam([{'params':malconv.parameters()}],lr=learning_rate)\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "if use_gpu:\n",
    "    malconv = malconv.cuda()\n",
    "    bce_loss = bce_loss.cuda()\n",
    "    sigmoid = sigmoid.cuda()\n",
    "\n",
    "\n",
    "step_msg = 'step-{}-loss-{:.6f}-acc-{:.4f}-time-{:.2f}'\n",
    "valid_msg = 'step-{}-tr_loss-{:.6f}-tr_acc-{:.4f}-val_loss-{:.6f}-val_acc-{:.4f}'\n",
    "log_msg = '{}, {:.6f}, {:.4f}, {:.6f}, {:.4f}, {:.2f}'\n",
    "history = {}\n",
    "history['tr_loss'] = []\n",
    "history['tr_acc'] = []\n",
    "\n",
    "log = open(log_file_path,'w')\n",
    "log.write('step,tr_loss, tr_acc, val_loss, val_acc, time\\n')\n",
    "\n",
    "valid_best_acc = 0.0\n",
    "total_step = 0\n",
    "step_cost_time = 0\n",
    "\n",
    "\n",
    "while total_step < max_step:\n",
    "    \n",
    "   \n",
    "    for step,batch_data in enumerate(dataloader):\n",
    "        start = time.time()\n",
    "        \n",
    "        adam_optim.zero_grad()\n",
    "        \n",
    "        cur_batch_size = batch_data[0].size(0)\n",
    "\n",
    "        exe_input = batch_data[0].cuda() if use_gpu else batch_data[0]\n",
    "        exe_input = Variable(exe_input.long(),requires_grad=False)\n",
    "        \n",
    "        label = batch_data[1].cuda() if use_gpu else batch_data[1]\n",
    "        label = Variable(label.float(),requires_grad=False)\n",
    "        \n",
    "        pred = malconv(exe_input)\n",
    "        loss = bce_loss(pred,label)\n",
    "        loss.backward()\n",
    "        adam_optim.step()\n",
    "        \n",
    "        history['tr_loss'].append(loss.cpu().data.numpy()[0])\n",
    "        history['tr_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))\n",
    "        \n",
    "        step_cost_time = time.time()-start\n",
    "        \n",
    "        if (step+1)%display_step == 0:\n",
    "            print(step_msg.format(total_step,np.mean(history['tr_loss']),\n",
    "                                  np.mean(history['tr_acc']),step_cost_time),end='\\r',flush=True)\n",
    "        total_step += 1\n",
    "\n",
    "        \n",
    "        if total_step%test_step ==0:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    history['val_loss'] = []\n",
    "    history['val_acc'] = []\n",
    "    history['val_pred'] = []\n",
    "    \n",
    "    for _,val_batch_data in enumerate(validloader):\n",
    "        cur_batch_size = val_batch_data[0].size(0)\n",
    "\n",
    "        exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]\n",
    "        exe_input = Variable(exe_input.long(),requires_grad=False)\n",
    "\n",
    "        label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]\n",
    "        label = Variable(label.float(),requires_grad=False)\n",
    "\n",
    "        pred = malconv(exe_input)\n",
    "        loss = bce_loss(pred,label)\n",
    "\n",
    "        history['val_loss'].append(loss.cpu().data.numpy()[0])\n",
    "        history['val_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))\n",
    "        history['val_pred'].append(list(sigmoid(pred).cpu().data.numpy()))\n",
    "\n",
    "    print(log_msg.format(total_step, np.mean(history['tr_loss']), np.mean(history['tr_acc']),\n",
    "                    np.mean(history['val_loss']), np.mean(history['val_acc']),step_cost_time),\n",
    "          file=log,flush=True)\n",
    "    \n",
    "    print(valid_msg.format(total_step,np.mean(history['tr_loss']),np.mean(history['tr_acc']),\n",
    "                           np.mean(history['val_loss']),np.mean(history['val_acc'])))\n",
    "    if valid_best_acc < np.mean(history['val_acc']):\n",
    "        valid_best_acc = np.mean(history['val_acc'])\n",
    "        torch.save(malconv,chkpt_acc_path)\n",
    "        print('Checkpoint saved at',chkpt_acc_path)\n",
    "        write_pred(history['val_pred'],valid_idx,pred_path)\n",
    "        print('Prediction saved at', pred_path)\n",
    "\n",
    "    history['tr_loss'] = []\n",
    "    history['tr_acc'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ed2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
